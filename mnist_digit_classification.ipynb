{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task 0: Introduction\n\nThe MNIST dataset is a benchmark dataset in machine learning and computer vision, consisting of 70,000 grayscale images of handwritten digits (0â€“9), each of size 28x28 pixels. The task is to classify each image into its corresponding digit, making it a multi-class classification problem. This challenge serves as an excellent introduction to deep learning, enabling the application of neural networks to solve real-world problems.\n\nIn this notebook, we will build a neural network using PyTorch to classify the MNIST digits. The solution involves loading and preprocessing the data, designing and training a deep learning model, evaluating its performance, and generating predictions for submission to Kaggle. This structured approach ensures reproducible results and facilitates understanding of fundamental deep learning concepts.","metadata":{}},{"cell_type":"markdown","source":"# Task 1: Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T02:47:00.602955Z","iopub.execute_input":"2024-11-19T02:47:00.603358Z","iopub.status.idle":"2024-11-19T02:47:01.770963Z","shell.execute_reply.started":"2024-11-19T02:47:00.603321Z","shell.execute_reply":"2024-11-19T02:47:01.769779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Importing Necessary Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch import nn, optim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:17:20.085246Z","iopub.execute_input":"2024-11-19T03:17:20.085596Z","iopub.status.idle":"2024-11-19T03:17:20.661446Z","shell.execute_reply.started":"2024-11-19T03:17:20.085567Z","shell.execute_reply":"2024-11-19T03:17:20.660325Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Task 2: Loading the Dataset","metadata":{}},{"cell_type":"code","source":"# Load the MNIST Dataset\ntrain_data_path = \"/kaggle/input/digit-recognizer/train.csv\"\ntest_data_path = \"/kaggle/input/digit-recognizer/test.csv\"\n\n# Load Training Data\ntrain_df = pd.read_csv(train_data_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:14:14.304113Z","iopub.execute_input":"2024-11-19T03:14:14.304476Z","iopub.status.idle":"2024-11-19T03:14:16.579234Z","shell.execute_reply.started":"2024-11-19T03:14:14.304446Z","shell.execute_reply":"2024-11-19T03:14:16.578215Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Task 3: Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"code","source":"# Exploratory Data Analysis\n# Display some basic statistics\nprint(train_df.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:14:33.643801Z","iopub.execute_input":"2024-11-19T03:14:33.644815Z","iopub.status.idle":"2024-11-19T03:14:35.674323Z","shell.execute_reply.started":"2024-11-19T03:14:33.644770Z","shell.execute_reply":"2024-11-19T03:14:35.673088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize a few samples from the dataset\ndef visualize_samples(dataframe, num_samples=6):\n    \"\"\"Visualizes random samples from the dataset.\"\"\"\n    samples = dataframe.sample(num_samples)\n    fig, axes = plt.subplots(1, num_samples, figsize=(15, 4))\n    for i, (idx, row) in enumerate(samples.iterrows()):\n        label = row['label']\n        image = row.drop('label').values.reshape(28, 28)\n        axes[i].imshow(image, cmap='gray')\n        axes[i].axis('off')\n        axes[i].set_title(f\"Label: {label}\")\n    plt.show()\n\nvisualize_samples(train_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:14:54.542198Z","iopub.execute_input":"2024-11-19T03:14:54.542588Z","iopub.status.idle":"2024-11-19T03:14:54.922228Z","shell.execute_reply.started":"2024-11-19T03:14:54.542554Z","shell.execute_reply":"2024-11-19T03:14:54.920965Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Task 4: Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Data Preprocessing with a Custom Dataset Class\nclass MNISTDataset(Dataset):\n    def __init__(self, dataframe: pd.DataFrame):\n        self.labels = dataframe['label'].values\n        self.images = dataframe.drop(columns=['label']).values.astype(np.float32) / 255.0\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        image = self.images[idx].reshape(28, 28)\n        label = self.labels[idx]\n        return torch.tensor(image, dtype=torch.float32), torch.tensor(label, dtype=torch.long)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:16:51.898342Z","iopub.execute_input":"2024-11-19T03:16:51.898736Z","iopub.status.idle":"2024-11-19T03:16:51.906457Z","shell.execute_reply.started":"2024-11-19T03:16:51.898701Z","shell.execute_reply":"2024-11-19T03:16:51.905233Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Task 5: Splitting Data into Training and Validation Sets","metadata":{}},{"cell_type":"code","source":"# Train-Validation Split\ntrain_set, val_set = train_test_split(train_df, test_size=0.2, random_state=42)\ntrain_dataset = MNISTDataset(train_set)\nval_dataset = MNISTDataset(val_set)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:17:25.104662Z","iopub.execute_input":"2024-11-19T03:17:25.105291Z","iopub.status.idle":"2024-11-19T03:17:25.490378Z","shell.execute_reply.started":"2024-11-19T03:17:25.105224Z","shell.execute_reply":"2024-11-19T03:17:25.489276Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:17:39.608942Z","iopub.execute_input":"2024-11-19T03:17:39.609879Z","iopub.status.idle":"2024-11-19T03:17:39.615159Z","shell.execute_reply.started":"2024-11-19T03:17:39.609839Z","shell.execute_reply":"2024-11-19T03:17:39.613960Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Task 6: Building the Neural Network Model","metadata":{}},{"cell_type":"code","source":"# Define the Neural Network Model\ninput_layer = 784\nhidden_layer1 = 128\nhidden_layer2 = 64\noutput_layer = 10\n\nmodel = nn.Sequential(\n    nn.Linear(input_layer, hidden_layer1),\n    nn.ReLU(),\n    nn.Linear(hidden_layer1, hidden_layer2),\n    nn.ReLU(),\n    nn.Linear(hidden_layer2, output_layer)\n)\n\n# Loss Function and Optimizer\nloss_function = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:35:28.310441Z","iopub.execute_input":"2024-11-19T03:35:28.311719Z","iopub.status.idle":"2024-11-19T03:35:28.329877Z","shell.execute_reply.started":"2024-11-19T03:35:28.311677Z","shell.execute_reply":"2024-11-19T03:35:28.328694Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Task 7: Training the Model","metadata":{}},{"cell_type":"code","source":"# Training the Model\ndef train_model(model, train_loader, val_loader, epochs=10):\n    \"\"\"Trains the neural network and evaluates it on validation data.\"\"\"\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        for images, labels in train_loader:\n            images = images.view(images.size(0), -1)\n            optimizer.zero_grad()\n            predictions = model(images)\n            loss = loss_function(predictions, labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        \n        # Validation Step\n        model.eval()\n        val_loss = 0\n        correct = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images = images.view(images.size(0), -1)\n                predictions = model(images)\n                val_loss += loss_function(predictions, labels).item()\n                correct += (predictions.argmax(1) == labels).sum().item()\n        \n        # Print Epoch Metrics\n        print(f\"Epoch {epoch+1}/{epochs}\")\n        print(f\"Train Loss: {total_loss/len(train_loader):.4f}\")\n        print(f\"Validation Loss: {val_loss/len(val_loader):.4f}\")\n        print(f\"Validation Accuracy: {100 * correct / len(val_dataset):.2f}%\")\n        print(\"-\" * 30)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_model(model, train_loader, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:18:29.960614Z","iopub.execute_input":"2024-11-19T03:18:29.961033Z","iopub.status.idle":"2024-11-19T03:18:54.800035Z","shell.execute_reply.started":"2024-11-19T03:18:29.960995Z","shell.execute_reply":"2024-11-19T03:18:54.798914Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Task 8: Preprocessing Test Data","metadata":{}},{"cell_type":"code","source":"# Evaluate on Test Data\ntest_df = pd.read_csv(test_data_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:23:21.160546Z","iopub.execute_input":"2024-11-19T03:23:21.160972Z","iopub.status.idle":"2024-11-19T03:23:22.960577Z","shell.execute_reply.started":"2024-11-19T03:23:21.160928Z","shell.execute_reply":"2024-11-19T03:23:22.959359Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare Test Dataset\nclass MNISTTestDataset(Dataset):\n    def __init__(self, dataframe: pd.DataFrame):\n        self.images = dataframe.values.astype(np.float32) / 255.0\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx].reshape(28, 28)\n        return torch.tensor(image, dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:23:42.118964Z","iopub.execute_input":"2024-11-19T03:23:42.119384Z","iopub.status.idle":"2024-11-19T03:23:42.125757Z","shell.execute_reply.started":"2024-11-19T03:23:42.119347Z","shell.execute_reply":"2024-11-19T03:23:42.124643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = MNISTTestDataset(test_df)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:23:44.603526Z","iopub.execute_input":"2024-11-19T03:23:44.603910Z","iopub.status.idle":"2024-11-19T03:23:44.669729Z","shell.execute_reply.started":"2024-11-19T03:23:44.603857Z","shell.execute_reply":"2024-11-19T03:23:44.668566Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Task 9: Making Predictions","metadata":{}},{"cell_type":"code","source":"# Make Predictions\ndef make_predictions(model, test_loader):\n    \"\"\"Predicts labels for the test dataset.\"\"\"\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for images in test_loader:\n            images = images.view(images.size(0), -1)\n            outputs = model(images)\n            predicted_labels = outputs.argmax(1).tolist()\n            predictions.extend(predicted_labels)\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:23:53.343889Z","iopub.execute_input":"2024-11-19T03:23:53.344832Z","iopub.status.idle":"2024-11-19T03:23:53.350517Z","shell.execute_reply.started":"2024-11-19T03:23:53.344791Z","shell.execute_reply":"2024-11-19T03:23:53.349342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions = make_predictions(model, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:24:09.391604Z","iopub.execute_input":"2024-11-19T03:24:09.391991Z","iopub.status.idle":"2024-11-19T03:24:09.928371Z","shell.execute_reply.started":"2024-11-19T03:24:09.391954Z","shell.execute_reply":"2024-11-19T03:24:09.927217Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Task 10: Creating the Submission File","metadata":{}},{"cell_type":"code","source":"# Save Results to Submission File\nsubmission = pd.DataFrame({\n    'ImageId': range(1, len(test_predictions) + 1),\n    'Label': test_predictions\n})\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file created: submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T03:24:12.090504Z","iopub.execute_input":"2024-11-19T03:24:12.090938Z","iopub.status.idle":"2024-11-19T03:24:12.125688Z","shell.execute_reply.started":"2024-11-19T03:24:12.090859Z","shell.execute_reply":"2024-11-19T03:24:12.124658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}